{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import time,datetime,timedelta\n",
    "import numpy as np\n",
    "import calendar\n",
    "\n",
    "# Define the path to your directory\n",
    "location = 'F:\\\\mansukh\\\\ratio_strategy_file\\\\raw_data_used_for_backtesting'\n",
    "#location = 'D:\\\\ratio_strategy_rawfile\\\\raw_data_used_for_backtesting_ratio_strategy'\n",
    "\n",
    "# Use glob to get all folder names in subdirectories that match the pattern\n",
    "all_folders = glob.glob(os.path.join(location, ''))\n",
    "\n",
    "                ######################## Sorting folders ##############################\n",
    "\n",
    "# Create a DataFrame from the list of file paths\n",
    "df_files = pd.DataFrame(all_folders, columns=['ddd'])\n",
    "\n",
    "df_files['date'] = df_files['ddd'].apply(lambda x: x.split('\\\\')[-1])\n",
    "# Replace underscores with spaces in the 'date' column\n",
    "df_files['date'] = df_files['date'].str.replace('_', ' ')\n",
    "\n",
    "df_files['date'] = pd.to_datetime(df_files['date'], format='%d %b %Y',dayfirst=True)\n",
    "\n",
    "# Sort the DataFrame by the 'date' column\n",
    "df_files = df_files.sort_values(by='date',ascending = True, ignore_index=True)\n",
    "\n",
    "df_files['date'] = pd.to_datetime(df_files['date'], format='%Y-%m-%d').dt.strftime('%d-%b-%Y')\n",
    "\n",
    "                        ##############################################\n",
    "    \n",
    "#df_straddle = pd.DataFrame()\n",
    "df_straddle_cleaned = pd.DataFrame()\n",
    "df_options_cleaned = pd.DataFrame()\n",
    "\n",
    "# List of holidays (example dates, update with actual holidays)\n",
    "holidays = ['2024-01-22', '2024-01-26','2024-03-08','2024-03-25','2024-03-29']  # Add more holiday dates as needed\n",
    "\n",
    "# Convert holiday dates to datetime objects\n",
    "holidays = [datetime.strptime(date, '%Y-%m-%d').date() for date in holidays]\n",
    "\n",
    "\n",
    "# Define a function to convert custom date formats to datetime\n",
    "def convert_custom_date(date_str):\n",
    "    if len(date_str) == 5 and date_str[2:].isdigit():  # Format is 24201\n",
    "        year = 2000 + int(date_str[:2])  # Assuming the year starts from 2000\n",
    "        month = int(date_str[2])\n",
    "        day = int(date_str[3:])\n",
    "        return datetime(year, month, day).strftime('%d-%b-%Y')\n",
    "    elif len(date_str) == 5 and date_str[2:].isalpha():  # Format is 24FEB\n",
    "        year = 2000 + int(date_str[:2])\n",
    "        month_str = date_str[2:].capitalize()\n",
    "        month = list(calendar.month_abbr).index(month_str.capitalize())\n",
    "        # Find the last Thursday of the month\n",
    "        last_day = calendar.monthrange(year, month)[1]\n",
    "        last_date = datetime(year, month, last_day).date()\n",
    "        while last_date.weekday() != calendar.THURSDAY:\n",
    "            last_date -= timedelta(days=1)\n",
    "        while last_date in holidays:\n",
    "            last_date -= timedelta(days=1)  # Move to the previous day if Thursday is a holiday\n",
    "        return last_date.strftime('%d-%b-%Y')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported date format: {date_str}\")\n",
    "                    \n",
    "            ######################## Process each folder ########################\n",
    "            \n",
    "for folder in df_files['ddd'][:]:\n",
    "    #print(folder)\n",
    "    # Get the date from the folder name\n",
    "    date = folder.split(\"\\\\\")[-1]  # -2 because the path ends with a slash\n",
    "\n",
    "    # Get all CSV files in the folder\n",
    "    all_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "    df_straddle = pd.DataFrame()\n",
    "    \n",
    "    # Initialize an empty DataFrame to store combined data\n",
    "    #df_straddle = pd.DataFrame()\n",
    "\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            if os.path.getsize(file) < 10720:\n",
    "                print(f\"Skipping file due to size < 10KB: {file}\")\n",
    "                continue\n",
    "           \n",
    "            # Read each CSV file\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            \n",
    "            # Skip empty DataFrames\n",
    "            if df.empty:\n",
    "                print(f\"Empty DataFrame: {file}\")\n",
    "                continue\n",
    "            \n",
    "            if len(df) <= 5:\n",
    "                print(f\"Skipping file {file} because it has only {len(df)} rows.\")\n",
    "                continue\n",
    "#             # Filter out rows where most of the data is missing\n",
    "#             df = df.dropna(thresh = int(df.shape[1] * 0.5))  # Adjust the threshold as needed\n",
    "            \n",
    "#             # Drop rows where all elements are missing\n",
    "#             df = df.dropna(how='all')\n",
    "            \n",
    "            #Skip the file if it has too many missing values or certain key columns are missing\n",
    "            if df.isnull().sum().sum() > df.size * 0.5:  # More than 50% missing values\n",
    "                print(f\"Skipping file due to too many missing values: {file}\")\n",
    "                continue\n",
    "\n",
    "            # List of key columns that must be present\n",
    "#             key_columns = ['Unnamed: 0', 'atm_leg1', 'contract_leg1']\n",
    "#             if not all(column in df.columns for column in key_columns):\n",
    "#                 print(f\"Skipping file due to missing key columns: {file}\")\n",
    "#                 continue\n",
    "            \n",
    "            df_straddle = pd.concat([df_straddle, df], ignore_index=True)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Skip the file if it's empty\n",
    "            print(f\"EmptyDataError: {file} is empty and has been skipped.\")\n",
    "        except Exception as e:\n",
    "            # Catch other potential errors and continue processing\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "   \n",
    "    if not df_straddle.empty:\n",
    "            df_straddle.rename(columns = {df_straddle.columns[0] : 'Datetime'} , inplace = True)\n",
    "            df_straddle['time'] = df_straddle['Datetime'].apply(lambda x: x.split(' ')[-1])\n",
    "            df_straddle['date'] = df_straddle['Datetime'].apply(lambda x: x.split(' ')[0])\n",
    "            df_straddle['option_type'] = df_straddle['contract_leg1'].apply(lambda x: x[-2:])\n",
    "            df_straddle['exp_date'] = df_straddle['contract_leg1'].apply(lambda x: x[5:10])\n",
    "\n",
    "            # Convert custom date format to standard datetime format\n",
    "            df_straddle['exp_date'] = df_straddle['exp_date'].apply(convert_custom_date)\n",
    "\n",
    "            columns = ['Datetime','date','time', 'atm_leg1','option_type','exp_date','contract_leg1', 'ltq_leg1', 'iv1_leg1', 'vtt_leg1',\n",
    "                       'ask_qty_leg1', 'ltp_high_leg1', 'ltp_low_leg1', 'theta_leg1',\n",
    "                       'oi_leg1', 'delta_leg1', 'iv2_leg1', 'ltp_close_leg1', 'ltp_open_leg1',\n",
    "                       'ask_leg1', 'bid_leg1', 'low_price_leg1', 'atp_leg1', 'high_price_leg1',\n",
    "                       'vega_leg1', 'close_price_leg1', 'bid_qty_leg1', 'open_price_leg1',\n",
    "                       'iv_leg1', 'gamma_leg1', 'ltt_leg1', 'underlying_price']\n",
    "            df_straddle = df_straddle[columns]\n",
    "            df_straddle = df_straddle.drop_duplicates(subset=columns).reset_index(drop=True)\n",
    "            # convert date column to datetime format\n",
    "            df_straddle['date'] = pd.to_datetime(df_straddle['date'] ,format='%Y-%m-%d', errors='coerce').dt.strftime('%d-%b-%Y')\n",
    "\n",
    "            # Fill NaN values in 'date' column with forward fill (ffill) and then backward fill (bfill)\n",
    "            df_straddle['date'] = df_straddle['date'].ffill()\n",
    "            df_straddle['time'] = pd.to_datetime(df_straddle['time'], format='mixed').dt.time\n",
    "            df_straddle['atm_leg1'] = df_straddle['atm_leg1'].astype(int)\n",
    "            df_straddle['atm'] = (round(df_straddle['underlying_price']/50)*50).astype(int) \n",
    "\n",
    "                            ########################### calculating atm straddle ########################3\n",
    "\n",
    "            # Separate DataFrames for CE and PE options\n",
    "            df_ce = df_straddle[df_straddle['option_type'] == 'CE'][['atm_leg1', 'date', 'time','exp_date', 'bid_leg1','ask_leg1']]\n",
    "            df_pe = df_straddle[df_straddle['option_type'] == 'PE'][['atm_leg1', 'date', 'time','exp_date', 'bid_leg1','ask_leg1']]\n",
    "\n",
    "            # Rename columns to distinguish between CE and PE\n",
    "            df_ce.rename(columns={'bid_leg1': 'bid_leg1_ce', 'ask_leg1': 'ask_leg1_ce'}, inplace=True)\n",
    "            df_pe.rename(columns={'bid_leg1': 'bid_leg1_pe', 'ask_leg1': 'ask_leg1_pe'}, inplace=True)\n",
    "\n",
    "            # Merge the CE and PE DataFrames on 'atm_leg1', 'date', and 'time'\n",
    "            df_merged = pd.merge(df_ce, df_pe, on=['atm_leg1', 'date', 'time','exp_date'])\n",
    "\n",
    "            # Calculate the straddle as the sum of 'bid_leg1_ce' and 'bid_leg1_pe'\n",
    "            df_merged['straddle_bid'] = df_merged['bid_leg1_ce'] + df_merged['bid_leg1_pe']\n",
    "            df_merged['straddle_ask'] = df_merged['ask_leg1_ce'] + df_merged['ask_leg1_pe']\n",
    "\n",
    "            df_merged.rename(columns={'atm_leg1': 'atm'}, inplace=True)\n",
    "            \n",
    "            # Merge the straddle values back to the original DataFrame\n",
    "            df_straddle = pd.merge(df_straddle, df_merged[['atm', 'date', 'time','exp_date', 'straddle_bid','straddle_ask']], \n",
    "                                   left_on=['atm', 'date', 'time','exp_date'], \n",
    "                                   right_on=['atm', 'date', 'time','exp_date'], \n",
    "                                   how='left')\n",
    "            \n",
    "            df_options_cleaned = pd.concat([df_options_cleaned,df_straddle], ignore_index=True)\n",
    "            \n",
    "            df_straddle = df_straddle.drop_duplicates(subset=['time']).reset_index(drop=True)\n",
    "            \n",
    "                                #######################################\n",
    "            \n",
    "            # Assuming you want to drop certain columns from drop and assign the result to df_straddle\n",
    "            df_straddle = df_straddle.drop(columns=['atm_leg1', 'option_type', 'contract_leg1',\n",
    "                                         'vtt_leg1', 'bid_qty_leg1', 'close_price_leg1', 'atp_leg1',\n",
    "                                         'delta_leg1', 'ltp_high_leg1', 'gamma_leg1', 'ltp_close_leg1',\n",
    "                                         'theta_leg1', 'iv_leg1', 'ltq_leg1', 'iv2_leg1', 'iv1_leg1',\n",
    "                                         'ltp_open_leg1', 'ask_leg1', 'low_price_leg1', 'ask_qty_leg1',\n",
    "                                         'open_price_leg1', 'vega_leg1', 'oi_leg1', 'high_price_leg1',\n",
    "                                         'ltp_low_leg1', 'bid_leg1', 'ltt_leg1'])\n",
    "\n",
    "            #df_straddle = df_straddle.ffill()\n",
    "            \n",
    "            # Define the time range\n",
    "            start_time = time(9, 15 )\n",
    "            end_time = time(15, 30 )\n",
    "\n",
    "            # Filter the DataFrame\n",
    "            df_straddle = df_straddle[(df_straddle['time'] >= start_time) & (df_straddle['time'] <= end_time)]\n",
    " \n",
    "            # Calculate the maximum values from the second row onwards\n",
    "            df_straddle.loc[1:, 'min_bid'] = df_straddle.loc[1:, 'straddle_bid'].expanding().min()\n",
    "            df_straddle.loc[1:, 'min_ask'] = df_straddle.loc[1:, 'straddle_ask'].expanding().min()\n",
    "            df_straddle.loc[1:, 'max_bid'] = df_straddle.loc[1:, 'straddle_bid'].expanding().max()\n",
    "            df_straddle.loc[1:, 'max_ask'] = df_straddle.loc[1:, 'straddle_ask'].expanding().max()\n",
    "            df_straddle.loc[1:, 'en1'] = np.where((df_straddle.loc[1:, 'straddle_bid'] + df_straddle.loc[1:, 'straddle_ask'])/2 - (df_straddle.loc[1:, 'min_bid'] + df_straddle.loc[1:, 'min_ask'])/2 > 10 , 10 , 0)\n",
    "\n",
    "            #Replace 0 values with NaN\n",
    "            df_straddle.replace(0, np.nan, inplace=True)\n",
    "            #Forward-fill the NaN values (which were originally 0)\n",
    "            df_straddle['en1'] = df_straddle['en1'].ffill()\n",
    "            df_straddle['straddle_bid'] = df_straddle['straddle_bid'].ffill()\n",
    "            df_straddle['straddle_ask'] = df_straddle['straddle_ask'].ffill()\n",
    "            \n",
    "            \n",
    "            df_straddle_cleaned = pd.concat([df_straddle_cleaned,df_straddle], ignore_index=True)\n",
    "    \n",
    "        ######################################### pre straddle value \n",
    "\n",
    "# Function to find previous straddle bid\n",
    "def find_previous_straddle_bid(row, df):\n",
    "    for days in range(1, 10):\n",
    "        previous_date = (pd.to_datetime(row['date'], format='%d-%b-%Y') - timedelta(days=days)).strftime('%d-%b-%Y')\n",
    "        exp_date = pd.to_datetime(row['exp_date'], format='%d-%b-%Y').strftime('%d-%b-%Y')\n",
    "        match = df[(df['date'] == previous_date) & (df['time'] == time(15, 28)) & (df['exp_date'] == exp_date)]\n",
    "        if not match.empty:\n",
    "            return match['straddle_bid'].values[0]\n",
    "            break\n",
    "    return np.nan\n",
    "def find_previous_straddle_ask(row, df):\n",
    "    for days in range(1, 10):\n",
    "        previous_date = (pd.to_datetime(row['date'], format='%d-%b-%Y') - timedelta(days=days)).strftime('%d-%b-%Y')\n",
    "        exp_date = pd.to_datetime(row['exp_date'], format='%d-%b-%Y').strftime('%d-%b-%Y')\n",
    "        match = df[(df['date'] == previous_date) & (df['time'] == time(15, 28, 0)) & (df['exp_date'] == exp_date)]\n",
    "        #print(match)\n",
    "        if not match.empty:\n",
    "            return match['straddle_ask'].values[0]  \n",
    "            break\n",
    "    return np.nan\n",
    "\n",
    "# Apply the functions to each row in df_index\n",
    "df_straddle_cleaned['pre_straddle_bid'] = df_straddle_cleaned.apply(lambda row: find_previous_straddle_bid(row , df_straddle_cleaned), axis=1)\n",
    "df_straddle_cleaned['pre_straddle_ask'] = df_straddle_cleaned.apply(lambda row: find_previous_straddle_ask(row , df_straddle_cleaned), axis=1)\n",
    "df_straddle_cleaned['cxt-mn/mx-mn'] = ((df_straddle_cleaned['straddle_bid'] + df_straddle_cleaned['straddle_ask'])/2 - (df_straddle_cleaned['min_bid'] + df_straddle_cleaned['min_ask'])/2) / ((df_straddle_cleaned['max_bid'] + df_straddle_cleaned['max_ask'])/2 - (df_straddle_cleaned['min_bid'] + df_straddle_cleaned['min_ask'])/2)\n",
    "\n",
    "# Define the path to save the combined CSV files\n",
    "save_path = \"F:\\\\mansukh\\\\ratio_strategy_file\\\\backtested_file\\\\straddle_option\"\n",
    "#save_path = 'D:\\\\ratio_strategy_rawfile\\\\backtested_file\\\\straddle_option'\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "#file_name = os.path.join(save_path, f\"straddle.csv\")\n",
    "# Define the file names and save paths for each DataFrame\n",
    "file_name_straddle = os.path.join(save_path, \"straddle.csv\")\n",
    "file_name_options = os.path.join(save_path, \"options.csv\")\n",
    "\n",
    "df_straddle_cleaned.to_csv(file_name_straddle, index=False)\n",
    "df_options_cleaned.to_csv(file_name_options, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
